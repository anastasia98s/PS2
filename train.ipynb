{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from global_dialog import DialogModel, gl_device, daten, tokenisierer, lemmatisierer, stemming, parameter_encoder, stopp_woerter, satz_entcoder, MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_woerter = []\n",
    "g_kategorien = []\n",
    "g_xy = []\n",
    "g_sprache = daten['data_dialoge']['sprache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in daten['data_dialoge']['dialoge']:\n",
    "    kategorie = dialog['kategorie']\n",
    "    g_kategorien.append(kategorie)\n",
    "\n",
    "    for muster in dialog['muster']:\n",
    "        w = tokenisierer(muster)\n",
    "        g_woerter.extend(w)\n",
    "        g_xy.append((w, kategorie))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 patterns\n",
      "6 tags: ['Begrüßungen', 'Verabschiedungen', 'Zeit', 'Wetter', 'Timer', 'Wikipedia']\n",
      "34 unique stemmed words: ['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa']\n"
     ]
    }
   ],
   "source": [
    "# g_woerter = [lemmatisierer(stemming(parameter_encoder(w))) for w in g_woerter if w not in stopp_woerter(g_sprache)]\n",
    "g_woerter = [lemmatisierer(stemming(a)) for w in g_woerter if w not in stopp_woerter(g_sprache) for a, _ in [parameter_encoder(w)]]\n",
    "\n",
    "\"\"\" g_woerter = sorted(set(g_woerter))\n",
    "g_kategorien = sorted(set(g_kategorien)) \"\"\"\n",
    "\n",
    "print(len(g_xy), \"patterns\")\n",
    "print(len(g_kategorien), \"tags:\", g_kategorien)\n",
    "print(len(g_woerter), \"unique stemmed words:\", g_woerter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Hallo', '!'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Wie', 'geht', \"'s?\"] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Auf', 'Wiedersehen', '!'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Tschüss', ',', 'bis', 'bald', '!'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Bis', 'zum', 'nächsten', 'Mal', '!'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Tschüss', '!'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Mach', \"'s\", 'gut', '!', 'Bis', 'bald', '!'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Wie', 'spät', 'ist', 'es', '?'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      " ['Könntest', 'du', 'die', 'Uhrzeit', 'sagen', '?'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \n",
      " ['Was', 'ist', 'die', 'aktuelle', 'Uhrzeit', '?'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.] \n",
      " ['das', 'Wetter', '[DATUM_EINHEIT]', 'in', '[ORT]', '?'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.] \n",
      " ['Stellen', 'sie', 'den', 'Timer', 'auf', '[NUMMER]', '[ZEIT_EINHEIT]'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] \n",
      " ['Wer', 'ist'] \n",
      "\n",
      "['hallo', 'wie', 'geht', \"'s?\", 'auf', 'wiederseh', 'tschuss', ',', 'bald', 'bi', 'nach', 'mal', 'tschuss', 'mach', 'gut', 'bi', 'bald', 'wie', 'spat', 'konnt', 'uhrzeit', 'sag', 'wa', 'aktuell', 'uhrzeit', 'wett', '[DATUM_EINHEIT]', '[ORT]', 'stell', 'tim', '[NUMMER]', '[ZEIT_EINHEIT]', 'wer', 'wa'] \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \n",
      " ['Was', 'ist'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for (mustersatz, kategorie) in g_xy: #for dari jumlah dari setiap muster\n",
    "\n",
    "    entcode_array = satz_entcoder(mustersatz, g_woerter)\n",
    "    X_train.append(entcode_array)\n",
    "\n",
    "    label = g_kategorien.index(kategorie)\n",
    "    y_train.append(label)\n",
    "\n",
    "    #print(g_woerter , \"\\n\" , entcode_array  , \"\\n\" , mustersatz, \"\\n\", kategorie, label, \"\\n\")\n",
    "\n",
    "    print(g_woerter , \"\\n\" , entcode_array  , \"\\n\" , mustersatz, \"\\n\")\n",
    "\n",
    "X_train = np.array(X_train) #array muster yg sudah di entcode\n",
    "y_train = np.array(y_train) #array kategori yg sudah bedasarkan index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_epochs = 1000\n",
    "\n",
    "h_batch_size = 8\n",
    "h_learning_rate = 0.001\n",
    "h_input_size = len(X_train[0]) # len(g_woerter)\n",
    "h_hidden_layer_1_size = 128\n",
    "h_hidden_layer_2_size = 64\n",
    "h_hidden_layer_3_size = 32\n",
    "h_output_size = len(g_kategorien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train) # len(g_xy) jumlah dari setiap muster\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "dialog_dataset = DialogDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dialog_dataset,\n",
    "                          batch_size=h_batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DialogModel(h_input_size, h_hidden_layer_1_size, h_hidden_layer_2_size, h_hidden_layer_3_size, h_output_size).to(gl_device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=h_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0051\n",
      "Epoch [200/1000], Loss: 0.0012\n",
      "Epoch [300/1000], Loss: 0.0002\n",
      "Epoch [400/1000], Loss: 0.0002\n",
      "Epoch [500/1000], Loss: 0.0001\n",
      "Epoch [600/1000], Loss: 0.0001\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(h_epochs):\n",
    "    for (woerter, labels) in train_loader:\n",
    "        woerter = woerter.to(gl_device)\n",
    "        labels = labels.to(dtype=torch.long).to(gl_device)\n",
    "\n",
    "        outputs = model(woerter)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{h_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = {\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"input_size\": h_input_size,\n",
    "    \"hidden_1_size\": h_hidden_layer_1_size,\n",
    "    \"hidden_2_size\": h_hidden_layer_2_size,\n",
    "    \"hidden_3_size\": h_hidden_layer_3_size,\n",
    "    \"output_size\": h_output_size,\n",
    "    \"woerter\": g_woerter,\n",
    "    \"kategorien\": g_kategorien\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei gespeichert in assets\\data.pth\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.save(data_save, MODEL_SAVE_PATH)\n",
    "    print(f'Datei gespeichert in {MODEL_SAVE_PATH}')\n",
    "except Exception as e:\n",
    "    print(f'Fehler beim Speichern der Datei: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
